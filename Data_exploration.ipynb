{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SihanTao/MethodForDataScience/blob/main/Data_exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT4RPNvxq6lT"
      },
      "source": [
        "#### Prerequisites\n",
        "\n",
        "- Basic familiarity with [Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)\n",
        "- Basic familiarity with [Pyplot](https://matplotlib.org/stable/tutorials/introductory/pyplot.html) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jw9cDN9sBLw"
      },
      "source": [
        "## Outline\n",
        "\n",
        "- [Section 1](#section-1): Data Loading\n",
        "- [Section 2](#section-2): Data Cleaning\n",
        "- [Section 3](#section-3): More Data Cleaning\n",
        "- [Section 4](#section-4): Descriptive Statistics\n",
        "- [Section 5](#section-5): Visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A9XJRkh3avA"
      },
      "source": [
        "# Data exploration\n",
        "\n",
        "In this notebook, we will learn some basic python functions which are helpful to gain a first overview whenever you face an unknown data set.\n",
        "\n",
        "You will work with a data set that consists of climbing data of [Mount Rainier](https://goo.gl/maps/WyAMb5BRBrgRECNB9). Mount Rainier is a 4,392 meters high stratovolcano in Washington, USA, and is considered difficult to summit. You must download the data set from Blackboard.\n",
        "\n",
        "We start with importing the required packages: numpy, pandas, and matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM-XTBpc3Udb"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhykjyll2Z_X"
      },
      "source": [
        "<a name=\"section-1\"></a>\n",
        "## Section 1: Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruc-V3Fe5kkg"
      },
      "source": [
        "Now we load the data set into a pandas data frame, which is standard the representation of a matrix with row and column names in python.\n",
        "\n",
        "_When using Google Colab, you first need to upload the data set to your notebook. This can be done by `files.upload()` from Google Colab's own python package `google.colab`._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecRlQvpl4W0h"
      },
      "outputs": [],
      "source": [
        "# only use when running this notebook in Google Colab, ignore this cell when running this notebook on your own machine\n",
        "from google.colab import files\n",
        "\n",
        "climbing_data = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf54iWpN4XwT"
      },
      "outputs": [],
      "source": [
        "# load data as pandas data frames\n",
        "climbing = pd.read_csv('climbing_statistics.csv', parse_dates=['Date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UIiD9qO7uIC"
      },
      "source": [
        "It is important to inform the [**read_csv**](https://pandas.pydata.org/pandas-docs/version/0.20.1/generated/pandas.read_csv.html) function about the columns corresponding to dates through `parse_dates` argument, to avoid loading the date as a string instead of datetime object. This is necessary to enable sorting rows by date columns and other operations related to date and time.\n",
        "\n",
        "The first step should always be to see the first few rows of your data set. This can easily be done with `.head()` when the object preceding it is a pandas data frame. \n",
        "\n",
        "In the parentheses of `.head()`, you can specify how many rows you would like to see (default is 5), and the function `.tail()` lets you see the last few rows.\n",
        "\n",
        "We print here the first 10 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7grMx4f4Xtn"
      },
      "outputs": [],
      "source": [
        "climbing.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRBWoXOK2SCT"
      },
      "source": [
        "<a name=\"section-2\"></a>\n",
        "\n",
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0KG2w6R8nLd"
      },
      "source": [
        "In the rows with indices **5** and **6** has gone something wrong. The **Date** and **Route** taken to the summit are exactly the same, so why has this not been summarised in one single row? Such things are very common in real data sets and are part of **data cleaning**. \n",
        "\n",
        "We will go through a couple of examples how this data set can be cleaned, i.e., made ready to be used by machine learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAllV8zz2FY3"
      },
      "source": [
        "### Method 1: Using higher-level Pandas operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Izn5hBx0Q_vH"
      },
      "outputs": [],
      "source": [
        "# aggregating the rows when Date and Route are identical\n",
        "climbing_clean_0 = climbing.groupby(['Date', 'Route']).sum().sort_values(['Date', 'Route'], ascending=False).reset_index()\n",
        "# recalculate the success percentage\n",
        "climbing_clean_0['Success Percentage'] = climbing_clean_0['Succeeded'] / climbing_clean_0['Attempted']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51ziOyy7xKvd"
      },
      "source": [
        "Now check the DataFrame after aggregating the rows by **Date** and **Route**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHabFVgkxIEn"
      },
      "outputs": [],
      "source": [
        "climbing_clean_0.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncghyG8F4mAO"
      },
      "source": [
        "### Method 2: Looping over the rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_pN_ecH4Xqg"
      },
      "outputs": [],
      "source": [
        "# create a sorted copy from climbing dataframe, with indices 0, 1, ..., n-1\n",
        "climbing_clean_1 = climbing.sort_values(['Date', 'Route'], ascending=False, ignore_index=True)\n",
        "\n",
        "# aggregating the rows when Date and Route are identical\n",
        "for index, row in climbing_clean_1.iterrows():\n",
        "    # skip the first row\n",
        "    if index == 0:\n",
        "        continue\n",
        "\n",
        "    if (climbing_clean_1.loc[index-1, 'Date'] == climbing_clean_1.loc[index, 'Date'] and \\\n",
        "        climbing_clean_1.loc[index-1, 'Route'] == climbing_clean_1.loc[index, 'Route']):\n",
        "      \n",
        "        climbing_clean_1.loc[index, 'Attempted'] += climbing_clean_1.loc[index-1, 'Attempted']\n",
        "        climbing_clean_1.loc[index, 'Succeeded'] += climbing_clean_1.loc[index-1, 'Succeeded']\n",
        "        \n",
        "    # recalculate the success percentage\n",
        "    climbing_clean_1.loc[index, 'Success Percentage'] = climbing_clean_1.loc[index, 'Succeeded'] / climbing_clean_1.loc[index, 'Attempted']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TJFFIwS4XnZ"
      },
      "outputs": [],
      "source": [
        "# check\n",
        "climbing_clean_1.tail(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrFDZePLBNlx"
      },
      "source": [
        "You can see that we were able to sum up the number of Attempted summits, but still have both rows in our data frame. Pandas has a one-line command to delete the first of these duplicates and only keep the last."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehT-sN1R4XkT"
      },
      "outputs": [],
      "source": [
        "climbing_clean_1 = climbing_clean_1.drop_duplicates(subset=['Date', 'Route'], keep='last')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1IR91jF4XhQ"
      },
      "outputs": [],
      "source": [
        "# check\n",
        "climbing_clean_1.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZubvEKlBuAu"
      },
      "source": [
        "Now we have the data frame that we wanted. The indices can simply be reset with `.reset_index()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzChXO68Br2T"
      },
      "outputs": [],
      "source": [
        "climbing_clean_1 = climbing_clean_1.reset_index(drop=True)  # with drop=True, drop the old index and create a new one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-53VVl6AB-em"
      },
      "outputs": [],
      "source": [
        "# check\n",
        "climbing_clean_1.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUBruaC1CvUG"
      },
      "source": [
        "Check if the results from Method 1 matches with results from Method 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVpjQErhCt_c"
      },
      "outputs": [],
      "source": [
        "# Any differences will be shown\n",
        "climbing_clean_0.compare(climbing_clean_1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PbJXuCH5JyG"
      },
      "source": [
        "<a name=\"section-3\"></a>\n",
        "\n",
        "## Section 3: More Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqe-G9J5CL40"
      },
      "source": [
        "Next, we find other manual mistakes in the data set. After having reviewed some random rows by hand, we find that on some dates there were more Succeeded summits than Attempted summits. This must be a mistake and we delete these rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtIUPLi0CAug"
      },
      "outputs": [],
      "source": [
        "# deleting rows, where number of successes is higher than number of attempts\n",
        "mistake_rows = climbing_clean_0[climbing_clean_0['Succeeded'] > climbing_clean_0['Attempted']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TysUPLv5DCCw"
      },
      "outputs": [],
      "source": [
        "# check\n",
        "mistake_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "op4Tlg4oDGKa"
      },
      "outputs": [],
      "source": [
        "# delete these rows\n",
        "climbing_clean_1 = climbing_clean_0.drop(index=mistake_rows.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDDHA5L5vK7_"
      },
      "outputs": [],
      "source": [
        "# deleted?\n",
        "climbing_clean_1[climbing_clean_1['Succeeded'] > climbing_clean_1['Attempted']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoWIApghvfls"
      },
      "source": [
        "Success! All rows are deleted which had a higher number of successes than attempts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kayQKDzbvUFD"
      },
      "outputs": [],
      "source": [
        "# reset index again\n",
        "climbing_clean_1 = climbing_clean_1.reset_index().drop(columns='index')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnanWRz9vnuM"
      },
      "outputs": [],
      "source": [
        "# check\n",
        "climbing_clean_1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqrbqVd97klE"
      },
      "source": [
        "<a name=\"section-4\"></a>\n",
        "\n",
        "## Section 4: Descriptive Statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BxjI0l2wlYp"
      },
      "source": [
        "It's always a good idea to compute some basic statistics of our data in the beginning. We start with simple means and standard deviations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXtrtgvP7Uvh"
      },
      "outputs": [],
      "source": [
        "climbing_clean_1.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnajJJ4P7xUg"
      },
      "source": [
        "<a name=\"section-5\"></a>\n",
        "\n",
        "## Section 5: Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKDouctAxxi_"
      },
      "source": [
        "We can also plot the attempts and successes over time. Our first column is already a date, but pandas has a special data type for dates, which it calls `datetime`.\n",
        "\n",
        "Let's first see in which format our column `Date` saved its values at. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLO2a3ouw-p5"
      },
      "outputs": [],
      "source": [
        "# check data types\n",
        "climbing_clean_1.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uexeSbj-y9Vg"
      },
      "source": [
        "This makes it now very easy to plot histograms over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGy2uN__y7zZ"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(14,10))\n",
        "\n",
        "for col in ['Attempted', 'Succeeded']:\n",
        "  ax.bar(climbing_clean_1['Date'], climbing_clean_1[col], alpha=0.5, label=col)\n",
        "ax.legend(fontsize=14)\n",
        "\n",
        "# rotates and right aligns the x labels, and moves the bottom of the axes up to make room for them\n",
        "fig.autofmt_xdate();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ER2yVdMCPQQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}